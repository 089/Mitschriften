% Vorlesung vom 23.11.2015
\renewcommand{\ldate}{2015-11-23}

\subsection{Beispiel}
\includegraphicsdeluxe{BspUnabhaengig1.jpg}{Beispiel Unabhängigkeit}{Beispiel Unabhängigkeit}{fig:BspUnabhaengig1}
$A$ und $B$ sind unabhängig. Dann sind auch $A$ und $\overline{B}$ unabhängig (Abb. \ref{fig:BspUnabhaengig1}). 

$P(A\cap \bar B)$
$=P(A) - P(A\cap B)$
$=P(A) - P(A) \cdot P(B)$
$=P(A)\cdot (1-P(B))$
$=P(A)\cdot P(\bar B)$

\begin{satz}
Sind $A_1, A_2, A_3, A_4, A_5$ unabhängig, dann auch z.B. $A_1, \overline{A_2}, \overline{A_3}, A_4, \overline{A_5}$ unabhängig (ohne Beweis).
\end{satz}

\subsection{Unabhängigkeit bei Produktexperimenten}
Es gibt n unabhängige Experimente $(\Omega_i, P_i)$ und $\Omega=\Omega_1 \times \Omega_2 \times ... \times \Omega_n$. Dann ist der Produktwahrscheinlichkeitsraum: 
$p(\underbrace{a_1}_{\in \Omega_1}, \underbrace{a_2}_{\in \Omega_2}, ..., a_n)$
$=p_1(a_1) \cdot p_2(a_2) \cdot ... \cdot p_n(a_n)$

$A_j = \cbr{(a_1,a_2,...,a_n) : a_j \in A_j^*}, A_j^* \subset \Omega_j$\\
$P(A_j) = P_j(A_j^*)$\\
Dann sind $A_1, A_2, ..., A_n$ unabhängig. 

\subsection{Beispiel 3mal würfeln}
$A_1^* = \cbr{1,2,3} \Rightarrow$ Im ersten Wurf 1, 2 oder 3. $A_1$ hingegen wäre $A_1 = (1/2/3, . , . )$.\\
$A_2^* = \cbr{5,6} \Rightarrow$ Im zweiten Wurf 5 oder 6.\\
$A_3^* = \cbr{4,5,6} \Rightarrow$ Im dritten Wurf 4, 5 oder 6.  \\
$P(A_1\cap A_2\cap A_3) = \frac{1}{2} \cdot \frac{1}{3} \cdot \frac{1}{2} \cdot = \frac{1}{12}$ 

\subsection{Vergröberung}
Es seien Ereignisse $A_1, A_2, ..., A_{10}$ unabhängig. Diese werden in zwei Blöcke unterteilt (1. Block: $A_1,...,A_5$, 2. Block: $A_6,...,A_{10}$). Aus jedem Block ein Ereignis konstruieren, z.B.: 
$B=(A_1\cup A_3) \cap \overline{A_5}$, $C=(A_7\cap \overline{A_9}) \cap A_{10}$. Dann sind B und C unabhängig. 

\subsection{Beispiel Lotto 6 aus 49}
Ein Spieler gibt jede Woche k verschiedene Reihen ab. Wie groß ist die Wahrscheinlichkeit, dass er in n Wochen mindestens einen \textit{Sechser} hat?

Anzahl der Möglichkeiten: $\binom {49} 6$

Wahrscheinlichkeit in einer Woche einen \textit{Sechser} zu haben, ist: $P(k) = \frac{k}{\binom {49} 6}$

Wahrscheinlichkeit in n Wochen keinen \textit{Sechser}: $(1-P(k))^n$ (unabhängig)

P(In n Wochen mindestens einen Sechser)
$=1-(1-P(k))^n$
mit z.B.: $n=2000$ (Wochen), $k=10$ (Spiele)
\underline{$=0.00142$}

\subsection{Beispiel Gruppenscreening}
Die Wahrscheinlichkeit für eine bestimmte Krankheit sei p (klein z.B. 0.02). Mit einer Blutuntersuchung kann man das feststellen:
\begin{itemize}
\item Einzeluntersuchung
\item Gruppenuntersuchung: Das Blut von k Personen wird gemischt. %\profnote{Jetzt wirds eklig und gefährlich.}
Falls gesund $\Rightarrow$ fertig, falls krank $\Rightarrow$ noch k Einzeluntersuchungen. 
\end{itemize}
Finde die optimale Gruppengröße. Wir definieren die Zufallsgröße Y als \textit{Anzahl der Untersuchungen}. Zwei Werte sind hier möglich: $Y=1$ und $Y=1+k$. 

$P(Y=1)$
$=(1-p)^k$

$P(Y=1+k)$
$=1-(1-p)^k$

$EY$
$=1\cdot (1-p)^k + (1+k) \cdot [1-(1-p)^k]$
$=(1-p)^k + (1+k) - (1+k)(1-p)^k$
$=(1-p)^k [1-(1+k)] + (1+k)$
$=(1+k) - k(1-p)^k$\\

minimiere: $\frac{EY}{k}$ ist die durchschnittliche Anzahl an Untersuchungen pro Person. 
$\frac{EY}{k}$ 
$=\frac{1+k}{k} - (1-p)^k$
$=\frac{1}{k} + 1 - (1-p)^k$

\subsection{Beispiel}
$P=0.1, k=4$
$\Rightarrow \frac{EY}{k}$
$=1 + \frac{1}{4} - (1 - 0.1)^4$
$=0.59$ also Ersparnis von 41\%.

$P=0.01, k=11$
$\Rightarrow \frac{EY}{k}$
$=1 + \frac{1}{11} - (1 - 0.01)^{11}$
$=0.20$ also Ersparnis von 80\%.

\subsection{p gegeben. Gruppengröße ausrechnen.}
$f(k)$
$= \frac{EY}{k}$
$= 1 + \frac{1}{k} - (1-p)^k$ minimieren: \\

\begin{tabular}{|c|c|c|c|}
\hline p & 0.2 & 0.1 & 0.01 \\ 
\hline opt. k & 3 & 4 & 11 \\ 
\hline Ersparnis & 18\% & 41\% & 80\% \\ 
\hline 
\end{tabular} 

\section{Gemeinsame Verteilung von Zufallsvariablen}
(Nur) Eine Zufallsvariable X:
\begin{tabular}{|c|c|c|c|}
\hline Wertebereich von X & 1 & 2 & 3 \\ 
\hline $p^x$ & $\frac 1 2$ & $\frac 1 4$ & $\frac 1 4$ \\ 
\hline 
\end{tabular} 


\includegraphicsdeluxe{ZweiZufVar1.jpg}{Zwei Zufallsvariablen}{Zwei Zufallsvariablen kann man unterschiedlich darstellen}{fig:ZweiZufVar1}
Zwei Zufallsvariablen X, Y (Abb. \ref{fig:ZweiZufVar1}): 

Wertebereich von X: $x_1, x_2, ..., x_r$\\
Wertebereich von Y: $y_1, y_2, ..., y_s$\\

\textbf{Verteilung von XY} \profnote{Man sagt auch gemeinsame Verteilung von X und Y.}

$P^{(X,Y)}(x_i,y_j) $
$=P(\cbr{\omega \in \Omega : Y(\omega) = x_i \textrm{ und } Y(\omega) = y_i})$

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline X/Y & $y_1$ & $y_2$ & $y_3$ & ... & $y_s$ & Verteilung von X\\ 
\hline $x_1$ & $p_{11}$ & $p_{12}$ & $p_{13}$ &  & $p_{1s}$ & $\sum$ \\ 
\hline $x_2$ & $p_{21}$ & $p_{22}$ & $p_{23}$ &  & $p_{2s}$ & $\sum$ \\ 
\hline $x_3$ & $p_{31}$ & $p_{32}$ & $p_{33}$ &  & $p_{3s}$ & $\sum$ \\ 
\hline ... &  &  &  &  &  & $\sum$ \\ 
\hline $x_r$ & $p_{r1}$ & $p_{r2}$ & $p_{r3}$ &  & $p_{rs}$ & $\sum$ \\ 
\hline Verteilung von Y & $\sum$  & $\sum$  & $\sum$  & $\sum$  & $\sum$  &  \\
\hline 
\end{tabular} 
